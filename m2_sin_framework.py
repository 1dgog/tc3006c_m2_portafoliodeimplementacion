# -*- coding: utf-8 -*-
"""m2_sin_framework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/1dgog/tc3006c_portafoliodeimplementacion/blob/main/m2_sin_framework.ipynb

# Módulo 2 Implementación de una técnica de aprendizaje máquina sin el uso de un framework

## Conexión con google drive
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# from google.colab import drive
# drive.mount("/content/gdrive")
# !pwd
# #put your own path in google drive
# %cd "/content/gdrive/MyDrive" 
# !ls

"""## Librerías

Se importan las librerías necesarias. sklearn solo se usa para hacer la división de datos de entrenamiento y prueba, y la matriz de confusión
"""

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
import math
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from google.colab import files

"""## Importacion de datos y columnas dummy

Se importa el CSV, se da nombre a las columnas, se forman columnas binarias dependiendo de clase ("index").
"""

columns = ["alcohol","malic_acid","ash","alcalinity_of_ash", "magnesium","total_phenols","flavanoids","nonflavanoid_phenols","proanthocyanins","color_intensity","hue","od280","proline"] # definir nombres de columna manualmente
df = pd.read_csv('wine.data',names = columns) # abrir el archivo de datos con los nombres dados para las columnas
df = df.reset_index() # se añade un nuevo indice para que el indice previo sea una clasificación que se usara en la siguiente figura.
df["clase1"] = df["index"]==1
df["clase1"] = df["clase1"].astype(int)
df["clase2"] = df["index"]==2
df["clase2"] = df["clase2"].astype(int)
df["clase3"] = df["index"]==3
df["clase3"] = df["clase3"].astype(int)

df

"""## Visualización binaria de datos."""

sns.lmplot(x='malic_acid',
           y='clase1',
           height=8,
           aspect=.8,
           data = df,
           fit_reg=False, 
           hue='clase1', 
           legend=True)
plt.title("Visualización binaria para clase 1")
plt.show()

sns.lmplot(x='malic_acid',
           y='clase2',
           height=8,
           aspect=.8,
           data = df,
           fit_reg=False, 
           hue='clase2', 
           legend=True)
plt.title("Visualización binaria para clase 1")
plt.show()

sns.lmplot(x='malic_acid',
           y='clase3',
           height=8,
           aspect=.8,
           data = df,
           fit_reg=False, 
           hue='clase3', 
           legend=True)
plt.title("Visualización binaria para clase 1")
plt.show()

"""## Función de clasificación

Se hace una función que considere dos características.
"""

def funcion_de_clasificacion2(x_train, x_valid, y_train, y_valid, x2_train, x2_valid, y2_train, y2_valid):
  
  # se hace una regresión logistica de orden 2

  h   = lambda x,theta,x2: 1/(1+np.exp(-(theta[0]+theta[1]*x+theta[2]*x2)))
  j_i = lambda x,y,theta,x2: y*np.log(h(x,theta,x2))+(1-y)*math.log(1-h(x,theta,x2))
  
  alpha = 0.05 ## es una proporcion de cuanto se mueve de acuerdo al error, porque era muy pequeño no se estaba moviendo prácticamente nada.

  n = len(y_train)

  theta = [2,1,0.5] # theta inicial
  print("theta inicial \n",theta)

  n_train = len(y_train)
  for idx in range(10000): ## Para mejorar aumentar el número de iteraciones
    acumDelta = []
    acumDeltaX = []
    acumDeltaX2 = []
    for x_i, y_i,x2_i in zip(x_train,y_train,x2_train):
      acumDelta.append(h(x_i,theta,x2_i)-y_i)
      acumDeltaX.append((h(x_i,theta,x2_i)-y_i)*x_i)
      acumDeltaX2.append((h(x_i,theta,x2_i)-y_i)*x2_i) # Acumular para el nuevo theta
      
    sJt0 = sum(acumDelta)
    sJt1 = sum(acumDeltaX)
    sJt2 = sum(acumDeltaX2)
    theta[0] = theta[0]-alpha/n*sJt0
    theta[1] = theta[1]-alpha/n*sJt1
    theta[2] = theta[2]-alpha/n_train*sJt2
  
  n_validate = len(y_valid)

  # Validación

  acumDelta = []
  for x_i, y_i,x2_i in zip(x_valid,y_valid,x2_valid):
    acumDelta.append(j_i(x_i,y_i,theta,x2_i))  

  sDelta = sum(acumDelta)
  J_validate = 1/(2*n_validate)*sDelta

  # Training
  
  acumDelta = []
  for x_i, y_i,x2_i in zip(x_train,y_train,x2_train):
    acumDelta.append(j_i(x_i,y_i,theta,x2_i)) 

  sDelta = sum(acumDelta)
  J_train = 1/(2*n_train)*sDelta

  print("J valid\n", J_validate)
  print("J entrenamiento \n",J_train)
  print("theta \n",theta)

  return theta

"""## Separación en subconjuntos y llamada a función de de clasificación

Se hace la división entre datos de entrenamiento, validación y prueba.
"""

print('-------------CLASE 1-----------------')

x_train1_a, x_r_a, y_train1_a, y_r_a = train_test_split(df["alcohol"], df['clase1'], test_size=0.33, random_state=0) ## el random state es semilla, se tomarán los mismos indices
x_valid1_a, x_test1_a, y_valid1_a, y_test1_a = train_test_split(x_r_a, y_r_a, random_state=0)
x_train1_b, x_r_b, y_train1_b, y_r_b = train_test_split(df["flavanoids"], df['clase1'], test_size=0.33, random_state=0)
x_valid1_b, x_test1_b, y_valid1_b, y_test1_b = train_test_split(x_r_b, y_r_b, random_state=0)
theta1 = funcion_de_clasificacion2(x_train1_a, x_valid1_a, y_train1_a, y_valid1_a, x_train1_b, x_valid1_b, y_train1_b, y_valid1_b)

print('-------------CLASE 2-----------------')

x_train2_a, x_r_a, y_train2_a, y_r_a = train_test_split(df["alcohol"], df['clase2'], test_size=0.33, random_state=0)
x_valid2_a, x_test2_a, y_valid2_a, y_test2_a = train_test_split(x_r_a, y_r_a, random_state=0)
x_train2_b, x_r_b, y_train2_b, y_r_b = train_test_split(df["flavanoids"], df['clase2'], test_size=0.33, random_state=0)
x_valid2_b, x_test2_b, y_valid2_b, y_test2_b = train_test_split(x_r_b, y_r_b, random_state=0)
theta2 = funcion_de_clasificacion2(x_train2_a, x_valid2_a, y_train2_a, y_valid2_a,x_train2_b, x_valid2_b, y_train2_b, y_valid2_b)

print('-------------CLASE 3-----------------')

x_train3_a, x_r_a, y_train3_a, y_r_a= train_test_split(df["alcohol"], df['clase3'], test_size=0.33, random_state=0)
x_valid3_a, x_test3_a, y_valid3_a, y_test3_a = train_test_split(x_r_a, y_r_a, random_state=0)
x_train3_b, x_r_b, y_train3_b, y_r_b = train_test_split(df["flavanoids"], df['clase3'], test_size=0.33, random_state=0)
x_valid3_b, x_test3_b, y_valid3_b, y_test2_b = train_test_split(x_r_b, y_r_b, random_state=0)
theta3 = funcion_de_clasificacion2(x_train3_a, x_valid3_a, y_train3_a, y_valid3_a,x_train3_b, x_valid3_b, y_train3_b, y_valid3_b)

# esto se usará para hacer la evaluación de las matrices de confusión haciendo de multicaso y no binario.
x_train_multiclase, x_r_multiclase, y_train_multiclase, y_r_multiclase = train_test_split(df["alcohol"], df['index'], test_size=0.33, random_state=0)
x_valid_multiclase, x_test_multiclase, y_valid_multiclase, y_test_multiclase = train_test_split(x_r_multiclase, y_r_multiclase, random_state=0)

print(theta3)

"""## Predicciones

Las variables maxValueIndex, toman la columna con el valor mayor del dataframe formado por los arrays comparacion1, comparacion2 y comparacion3 (que toman el valor de las características y theta para la regresión logistica). Este se usa para después hacer la matriz de confusión multicaso.
"""

## ----------------------------ENTRENAMIENTO--------------------------------------------##

comparacion1 = np.array(1/(1+np.exp(-(theta1[0]+theta1[1]*x_train1_a+theta1[2]*x_train1_b))))
comparacion2 = np.array(1/(1+np.exp(-(theta2[0]+theta2[1]*x_train1_a+theta2[2]*x_train1_b))))
comparacion3 = np.array(1/(1+np.exp(-(theta3[0]+theta3[1]*x_train1_a+theta3[2]*x_train1_b))))

comparacion_train = {'1': comparacion1.transpose(),'2': comparacion2.transpose(),'3': comparacion3.transpose()}

df2_train = pd.DataFrame(comparacion_train)

maxValueIndex_train_1 = df2_train.idxmax(axis = 1).astype(int)
print(maxValueIndex_train_1)

## ----------------------------VALID--------------------------------------------##

comparacion1 = np.array(1/(1+np.exp(-(theta1[0]+theta1[1]*x_valid1_a+theta1[2]*x_valid1_b))))
comparacion2 = np.array(1/(1+np.exp(-(theta2[0]+theta2[1]*x_valid1_a+theta2[2]*x_valid1_b))))
comparacion3 = np.array(1/(1+np.exp(-(theta3[0]+theta3[1]*x_valid1_a+theta3[2]*x_valid1_b))))

comparacion_valid = {'1': comparacion1.transpose(),'2': comparacion2.transpose(),'3': comparacion3.transpose()}

df2_valid = pd.DataFrame(comparacion_valid)

maxValueIndex_valid_1 = df2_valid.idxmax(axis = 1).astype(int)
print(maxValueIndex_valid_1)

## ----------------------------TEST--------------------------------------------##

comparacion1 = np.array(1/(1+np.exp(-(theta1[0]+theta1[1]*x_test1_a+theta1[2]*x_test1_b))))
comparacion2 = np.array(1/(1+np.exp(-(theta2[0]+theta2[1]*x_test1_a+theta2[2]*x_test1_b))))
comparacion3 = np.array(1/(1+np.exp(-(theta3[0]+theta3[1]*x_test1_a+theta3[2]*x_test1_b))))

comparacion_test = {'1': comparacion1.transpose(),'2': comparacion2.transpose(),'3': comparacion3.transpose()}

df2_test = pd.DataFrame(comparacion_test)

maxValueIndex_test_1 = df2_test.idxmax(axis = 1).astype(int)
print(maxValueIndex_test_1)

"""## Visualización de predicciones (conjunto de prueba) para README.md"""

visualizacion_predicciones = pd.concat([pd.DataFrame(np.asarray(y_test_multiclase)), 
                                        pd.DataFrame(np.asarray(maxValueIndex_test_1)),
                                        pd.DataFrame(np.asarray(x_test1_a)),
                                        pd.DataFrame(np.asarray(x_test1_b)),
                                        df2_test], 
                                       axis=1)
visualizacion_predicciones.columns = ["Real","Prediccion","alcohol","flavanoids","1","2","3"]

print(visualizacion_predicciones.to_markdown())

"""## Matrices de confusión

Se presenta la matriz de confusión con base en los valores obtenidos de las pruebas. Se obtiene usando la librería de sklearn importada más arriba.
"""

cf_train = confusion_matrix(y_train_multiclase, maxValueIndex_train_1)
cf_valid = confusion_matrix(y_valid_multiclase, maxValueIndex_valid_1)
cf_test = confusion_matrix(y_test_multiclase,maxValueIndex_test_1)

"""### Visualización de matrices de confusión con sns"""

# para que las columnas y filas vayan de 1 a 3 y no 0 a 2
df_cf_train = pd.DataFrame(cf_train, index = [1, 2, 3],
                  columns = [1, 2, 3])
df_cf_valid = pd.DataFrame(cf_valid, index = [1, 2, 3],
                  columns = [1, 2, 3])
df_cf_test = pd.DataFrame(cf_valid, index = [1, 2, 3],
                  columns = [1, 2, 3])

group_names = ["Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_train.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_train.flatten()/np.sum(cf_train)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

labels = np.asarray(labels).reshape(3,3)
sns.heatmap(df_cf_train,annot=labels, fmt="", cmap='Blues')
plt.title("Matriz de confusión para subconjunto de entrenamiento")
plt.savefig('cf_train.png') 
files.download("cf_train.png")
plt.show()

group_names = ["Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_valid.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_valid.flatten()/np.sum(cf_train)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

labels = np.asarray(labels).reshape(3,3)
sns.heatmap(df_cf_valid,annot=labels, fmt="", cmap='Blues')
plt.title("Matriz de confusión para subconjunto de validación")
plt.savefig('cf_valid.png') 
files.download("cf_valid.png")
plt.show()

group_names = ["Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_test.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_test.flatten()/np.sum(cf_train)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

labels = np.asarray(labels).reshape(3,3)
sns.heatmap(df_cf_test,annot=labels, fmt="", cmap='Blues')
plt.title("Matriz de confusión para subconjunto de prueba")
plt.savefig('cf_test.png') 
files.download("cf_test.png")
plt.show()