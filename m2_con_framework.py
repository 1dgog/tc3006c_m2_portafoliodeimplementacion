# -*- coding: utf-8 -*-
"""m2_con_framework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/1dgog/tc3006c_portafoliodeimplementacion/blob/main/m2_con_framework.ipynb

# Módulo 2 Uso de framework o biblioteca de aprendizaje máquina para la implementación de una solución.

## Importación de librerías y dataset
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount("/content/gdrive")
!pwd
#put your own path in google drive
# %cd "/content/gdrive/MyDrive"
!ls

"""### Librerias"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns # para hacer visualizacion
from sklearn.neural_network import MLPClassifier # para clasificacion
from sklearn.model_selection import train_test_split # para separacion de datos
from sklearn import metrics
from sklearn.metrics import confusion_matrix # para matrices de confusion
from sklearn.model_selection import cross_val_predict
from google.colab import files # para descargar figuras

"""### Nombramiento de dataset y visualización inicial"""

columns = ["alcohol","malic_acid","ash","alcalinity_of_ash", "magnesium","total_phenols","flavanoids","nonflavanoid_phenols","proanthocyanins","color_intensity","hue","od280","proline"] # definir nombres de columna manualmente
df = pd.read_csv('wine.data',names = columns) # abrir el archivo de datos con los nombres dados para las columnas
df = df.reset_index() # se añade un nuevo indice para que el indice previo sea una clasificación que se usara en la siguiente figura.
print(df.info())
print(df.head())

"""Se nombran los datasets de entrada y salida con el que será entrenado el modelo. Se están tomando todas las características."""

dfInput = df[["alcohol","malic_acid","ash","alcalinity_of_ash", "magnesium","total_phenols","flavanoids","nonflavanoid_phenols","proanthocyanins","color_intensity","hue","od280","proline"]]
dfOutput = df[["index"]]

"""## Aplicación de redes neuronales, scores y matrices de confusion

### Separación de datos de entrenamiento, validacion y datos de prueba
"""

X_train, X_r, y_train, y_r = train_test_split(dfInput, dfOutput, random_state=0)
X_valid, X_test, y_valid, y_test = train_test_split(X_r, y_r, random_state=0)

"""### Obtención de Scores y matrices de confusión

Se hizo un ciclo for en el que se inicia con 5 capas ocultas y va hasta cuarenta con pasos de 5.

Lo mismo para el segundo que especifica el tamaño de la capa.

Estos datos se almacenan en vectores, tanto para los datos de entrenamiento como para los de test.
"""

scores_train = []
scores_valid= []
scores_test = []
almacenamiento_conf_mat_train = []
almacenamiento_conf_mat_valid = []
almacenamiento_conf_mat_test = []

cont = 0

for ii in range (5,40, 5):
  if cont == 1:
    scores_train.append(jj_scores_train)
    scores_valid.append(jj_scores_valid) # aqui estaba el error
    scores_test.append(jj_scores_test)
    almacenamiento_conf_mat_train.append(jj_mc_train)
    almacenamiento_conf_mat_valid.append(jj_mc_valid) # aqui estaba el error
    almacenamiento_conf_mat_test.append(jj_mc_test)

  cont = 1
  
  jj_scores_train = []
  jj_scores_valid = []
  jj_scores_test = []
  jj_mc_train = []
  jj_mc_valid = []
  jj_mc_test = []

  for jj in range(5,40,5):
    cross_val_predict,
    nnRE = MLPClassifier(hidden_layer_sizes=(ii,jj),  ## cambiar estos parámetros
                        activation='logistic', verbose=False, solver='adam',
                        learning_rate='adaptive', max_iter=2000)
    nnRE.fit(X_train,y_train)
    jj_scores_train.append(nnRE.score(X_train, y_train))
    jj_scores_valid.append(nnRE.score(X_valid, y_valid))
    jj_scores_test.append(nnRE.score(X_test, y_test))
    
    jj_mc_train.append(confusion_matrix(y_train,cross_val_predict(nnRE,X_train,y_train, cv = 10)))
    jj_mc_valid.append(confusion_matrix(y_valid,cross_val_predict(nnRE,X_valid,y_valid, cv = 10)))
    jj_mc_test.append(confusion_matrix(y_test,cross_val_predict(nnRE,X_test,y_test, cv = 5)))

"""Se hace presenta el cambio de los scores con respecto a los parametros ii y jj del loop, que corresponden al número de capas ocultas y su extención"""

print("--------------PUNTAJES--------------")
print(np.array(scores_train))
print("--------------")
print(np.array(scores_valid))
print("--------------")
print(np.array(scores_test))

print("-------------- MATRICES DE CONFUSION--------------")
np.info(np.array(scores_train))
print("--------------")
np.info(np.array(scores_valid))
print("--------------")
np.info(np.array(scores_test))

print(np.array(almacenamiento_conf_mat_train))
print("--------------")
print(np.array(almacenamiento_conf_mat_valid))
print("--------------")
print(np.array(almacenamiento_conf_mat_test))

"""## Predicciones para README.md"""

hola = pd.DataFrame(cross_val_predict(nnRE,X_test,y_test, cv = 5))
visualizacion_predicciones = pd.concat([X_test, 
                                        y_test,
                                        hola.reset_index(drop=True)],
                                       axis=1)

"""## Visualización de matrices de confusión para modelo simple y modelo refinado"""

df_cf_test_ini = pd.DataFrame(np.asarray([[0, 2, 0], [0, 7, 0],[0, 3, 0]]), index = [1, 2, 3],
                  columns = [1, 2, 3])
group_names = ["Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto"]
group_counts = ["{0:0.0f}".format(value) for value in
                np.array([[0, 2, 0], [0, 7, 0],[0, 3, 0]]).flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     np.array([[0, 2, 0], [0, 7, 0],[0, 3, 0]]).flatten()/np.sum(np.array([[0, 2, 0], [0, 7, 0],[0, 3, 0]]))]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

labels = np.asarray(labels).reshape(3,3)
sns.heatmap(df_cf_test_ini,annot=labels, fmt="", cmap='Blues')
plt.title("Matriz de confusión para modelo inicial con subconjunto de prueba \n(5 capas ocultas, 5 neuronas por capa)")
plt.savefig('cf_test_con_framework_ini.png') 
files.download("cf_test_con_framework_ini.png")
plt.show()

df_cf_test_ref = pd.DataFrame(np.asarray([[1, 0, 1], [0, 7, 0],[1, 1, 1]]), index = [1, 2, 3],
                  columns = [1, 2, 3])
group_names = ["Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto","Incorrecto","Incorrecto","Incorrecto","Correcto"]
group_counts = ["{0:0.0f}".format(value) for value in
                np.array([[1, 0, 1], [0, 7, 0],[1, 1, 1]]).flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     np.array([[1, 0, 1], [0, 7, 0],[1, 1, 1]]).flatten()/np.sum(np.array([[1, 0, 1], [0, 7, 0],[1, 1, 1]]))]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

labels = np.asarray(labels).reshape(3,3)
sns.heatmap(df_cf_test_ref,annot=labels, fmt="", cmap='Blues')
plt.title("Matriz de confusión para modelo refinado con subconjunto de prueba \n(35 capas ocultas, 5 neuronas por capa)")
plt.savefig('cf_test_con_framework_ref.png') 
files.download("cf_test_con_framework_ref.png")
plt.show()

"""## Visualización de scores"""

cont = 5
for a in range(0,len(np.array(scores_train)),1):
  plt.plot(np.array(scores_train)[a], label='%s capas' % cont)
  cont += 5
ax = plt.gca()
ax.set_ylim([np.min(scores_train)-0.1, np.max(scores_train)])
plt.legend()
plt.title('Puntajes para datos de entrenamiento (train)')
plt.ylabel("Puntaje")
plt.xlabel("Iteración de jj (número de unidades en capa oculta x5)")
plt.savefig('scores_train.pdf') 
files.download("scores_train.pdf")
plt.show()

cont = 5
for a in range(0,len(np.array(scores_valid)),1):
  plt.plot(np.array(scores_valid)[a], label='%s capas' % cont)
  cont += 5
ax = plt.gca()
ax.set_ylim([np.min(scores_valid)-0.1, np.max(scores_valid)])
plt.legend()
plt.title('Puntajes para datos de validacion (valid)')
plt.ylabel("Puntaje")
plt.xlabel("Iteración de jj (número de unidades en capa oculta x5)")
plt.savefig('scores_valid.pdf') 
files.download("scores_valid.pdf")
plt.show()

cont = 5
for a in range(0,len(np.array(scores_test)),1):
  plt.plot(np.array(scores_test)[a], label='%s capas' % cont)
  cont += 5
ax = plt.gca()
ax.set_ylim([np.min(scores_test)-.1, np.max(scores_test)])
plt.legend()
plt.title('Puntajes para datos de prueba (test)')
plt.ylabel("Puntaje")
plt.xlabel("Iteración de jj (número de unidades en capa oculta x5)")
plt.savefig('scores_test.pdf') 
files.download("scores_test.pdf")
plt.show()

"""## Visualización de cambio con respecto a matrices de confusión

Para resultados acertados
"""

sum_correcto_train = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_correcto_train.append(np.trace(np.array(almacenamiento_conf_mat_train)[ii,jj]))
sum_correcto_valid = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_correcto_valid.append(np.trace(np.array(almacenamiento_conf_mat_valid)[ii,jj]))
sum_correcto_test = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_correcto_test.append(np.trace(np.array(almacenamiento_conf_mat_test)[ii,jj]))

print(np.array(sum_correcto_train).transpose())
print(np.array(sum_correcto_valid).transpose())
print(np.array(sum_correcto_test).transpose())

cont = 5
for a in range(0,len(np.array(sum_correcto_train)),6):
  plt.plot(np.array(sum_correcto_train)[a:a+6], label='%s capas' % cont)
  cont += 5
plt.legend()
plt.title('Predicciones correctas (train)')
plt.ylabel("Predicciones correctas")
plt.xlabel("Iteración de jj (número de unidades en capa oculta x5)")
plt.savefig('acertados_train.pdf')
files.download("acertados_train.pdf")
plt.show()

cont = 5
for a in range(0,len(np.array(sum_correcto_valid)),6):
  plt.plot(np.array(sum_correcto_valid)[a:a+6], label='%s capas' % cont)
  cont += 5
plt.legend()
plt.title('Predicciones correctas (valid)')
plt.ylabel("Predicciones correctas")
plt.xlabel("Iteración de jj (número de unidades en capa oculta x5)")
plt.savefig('acertados_valid.pdf') 
files.download("acertados_valid.pdf")
plt.show()


cont = 5
for a in range(0,len(np.array(sum_correcto_test)),6):
  plt.plot(np.array(sum_correcto_test)[a:a+6], label='%s capas' % cont)
  cont += 5
plt.legend()
plt.ylabel("Predicciones correctas")
plt.title('Predicciones correctas (test)')
plt.xlabel("Iteración de jj (número de unidades en capa oculta x5)")
plt.savefig('acertados_test.pdf')
files.download("acertados_test.pdf")
plt.show()

"""Para resultados equivocados, se toma la resta de la suma total de los datos en la matriz, restada a los datos correctos"""

sum_incorrecto_train = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_incorrecto_train.append(np.sum(np.array(almacenamiento_conf_mat_train)[ii,jj])-np.trace(np.array(almacenamiento_conf_mat_train)[ii,jj]))

sum_incorrecto_valid = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_incorrecto_valid.append(np.sum(np.array(almacenamiento_conf_mat_valid)[ii,jj])-np.trace(np.array(almacenamiento_conf_mat_valid)[ii,jj]))

sum_incorrecto_test = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_incorrecto_test.append(np.sum(np.array(almacenamiento_conf_mat_test)[ii,jj])-np.trace(np.array(almacenamiento_conf_mat_test)[ii,jj]))

print(np.array(sum_incorrecto_train).transpose())
print(np.array(sum_incorrecto_valid).transpose())
print(np.array(sum_incorrecto_test).transpose())

cont = 0
for a in range(0,len(np.array(sum_incorrecto_train)),7):
  cont += 5
  plt.plot(np.array(sum_incorrecto_train)[a:a+7], label='%s capas' % cont)
plt.legend()
plt.ylabel("Predicciones incorrectas")
plt.title('Predicciones incorrectas (test)')
plt.xlabel("Iteración de jj (número de unidades en capa oculta x5)")
plt.savefig('incorrectas_train.pdf')
files.download("incorrectas_train.pdf")
plt.show()

cont = 0
for a in range(0,len(np.array(sum_incorrecto_valid)),7):
  cont += 5
  plt.plot(np.array(sum_incorrecto_valid)[a:a+7], label='%s capas' % cont)
plt.legend()
plt.ylabel("Predicciones incorrectas")
plt.title('Predicciones incorrectas (test)')
plt.xlabel("Iteración de jj (número de unidades en capa oculta x5)")
plt.savefig('incorrectas_valid.pdf')
files.download("incorrectas_valid.pdf")
plt.show()

cont = 0
for a in range(0,len(np.array(sum_incorrecto_test)),6):
  cont += 5
  plt.plot(np.array(sum_incorrecto_test)[a:a+7], label='%s capas' % cont)
plt.legend()
plt.ylabel("Predicciones incorrectas")
plt.title('Predicciones incorrectas (test)')
plt.xlabel("Iteración de jj (número de unidades en capa oculta x5)")
plt.savefig('incorrectas_test.pdf')
files.download("incorrectas_test.pdf")
plt.show()

"""## Notas de asesoría 1.

Sesgo y varianza, estan relacionados, tiene que ver con el overfitting. Si tiene poco sesgo es porque tiene mucha varianza, y viceversa

Poner en terminos de bajo, medio y alto. 

No es necesario que sea de varios frameworks, con uno basta.}

Se pueden hacer gráficas de como cambia el score.+

## Asesoría 2

Poner print de valores de entrada, y valores predecidos y esperados.
"""